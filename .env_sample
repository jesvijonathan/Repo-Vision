# Llama server settings
model=DeepSeek-R1-Distill-Qwen-1.5B-Q8_0.gguf
model_llama_ctx_size=1024
model_llama_mlock=
model_llama_temp=
model_llama_top_k=
model_llama_top_p=
model_llama_repeat_penalty=
model_llama_batch_size=
model_llama_port=
model_llama_host=
model_llama_threads=
model_llama_mmap=
model_llama_log=
